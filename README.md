<img width="1366" height="768" alt="image" src="https://github.com/user-attachments/assets/b4f48636-b4fd-48d8-b3e5-e7b94f8a5664" />ğŸ“˜ RAG Upload Demo â€“ Documentation
ğŸ”¹ Overview

This project demonstrates how to build a Retrieval-Augmented Generation (RAG) pipeline that:
Accepts a document (PDF, TXT, DOCX).
Extracts and chunks the text.
Generates vector embeddings using OpenAI Embedding Models (text-embedding-3-small).
Stores embeddings in Pinecone (vector database).
Stores metadata and relationships in Neo4j (graph database).
Provides a Streamlit web UI for file upload and monitoring.
The goal is to prepare data for downstream tasks such as semantic search, question-answering, or knowledge graph exploration.

ğŸ”¹ Architecture
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   Upload    â”‚  â† User uploads PDF/TXT/DOCX
                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Text Loader   â”‚ (PDFminer / python-docx / file read)
                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Chunking     â”‚ (smart chunk ~500-1000 tokens)
                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   OpenAI Embeddings API   â”‚ (text-embedding-3-small)
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pinecone Index â”‚                â”‚   Neo4j Graph  â”‚
â”‚ (Vector Store) â”‚                â”‚ (Metadata +    â”‚
â”‚ semantic searchâ”‚                â”‚ Relationships) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
<img width="1366" height="768" alt="image" src="https://github.com/user-attachments/assets/81c37f01-d590-4efc-94fa-7bbf45f7a6a1" />


ğŸ”¹ Prerequisites

Python 3.10+
Dependencies:
pip install streamlit openai pinecone-client neo4j python-docx pypdf2 python-dotenv

Accounts & Keys:
OpenAI API Key
Pinecone API Key
Neo4j Aura
 (Free graph DB)

 ğŸ”¹ Environment Setup
Create a .env file:
ğŸ”¹ Environment Setup
OPENAI_API_KEY=your_openai_key

PINECONE_API_KEY=your_pinecone_key
PINECONE_INDEX_NAME=rag-demo-index

NEO4J_URI=neo4j+ssc://<your-db-id>.databases.neo4j.io
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password

ğŸ”¹ Streamlit UI (app.py)
Uploads a document.
Extracts & chunks text.
Generates embeddings.
Stores in Pinecone + Neo4j.
Shows progress + preview.

Run:
streamlit run app.py

Then open: http://localhost:8501

ğŸ”¹ Backend Functions
Inside rag_upload.py you should have utilities like:
load_text(file) â†’ Reads PDF/TXT/DOCX, returns plain text.
smart_chunk(text) â†’ Splits into smaller overlapping chunks.
embed_chunks_openai(chunks) â†’ Gets embeddings from OpenAI.
ensure_pinecone_index(pc, name, dimension) â†’ Creates Pinecone index if not exists.
upsert_to_pinecone(pc, index_name, chunks, vectors, doc_id) â†’ Stores vectors.
upsert_to_neo4j(driver, chunks, vectors, meta, doc_id) â†’ Stores graph nodes.

ğŸ”¹ Example Flow

Upload sample.pdf (668 chars).
System creates 1 chunk.
Generates 1536-dim embeddings with text-embedding-3-small.
Stores vector in Pinecone index (rag-demo-index).
Creates document + chunk nodes in Neo4j graph.
Confirms success in UI.

ğŸ”¹ Neo4j Graph Schema
(:Document {id, filename, size})
(:Chunk {id, text, embedding_dim})

Relationship: (:Document)-[:HAS_CHUNK]->(:Chunk)
This allows queries like:
MATCH (d:Document)-[:HAS_CHUNK]->(c:Chunk)
RETURN d.filename, count(c) as chunks

ğŸ”¹ Pinecone Index Schema
Vector IDs: ${doc_id}::chunk_${i}
Vector values: 1536-dim embeddings.
Metadata: { "doc_id": ..., "chunk_id": ..., "text": ... }

